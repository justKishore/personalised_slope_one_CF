{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and load necesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and load these\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "df = pd.read_csv('ml-100k/u.data', names=['user_id', 'item_id', 'rating', 'timestamp'], sep='\\t')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset\n",
    "## Random Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Construct the rating matrix based on train_df:\n",
      "[[0. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]]\n",
      "Construct the rating matrix based on test_df:\n",
      "[[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state = 10)\n",
    "train_df, test_df\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = np.zeros((n_users, n_items))\n",
    "for row in train_df.itertuples():\n",
    "    train_ds[row[1]-1, row[2]-1] = row[3]\n",
    "# train_ds = pd.DataFrame(train_ds)\n",
    "\n",
    "# Testing Dataset\n",
    "test_ds = np.zeros((n_users, n_items))\n",
    "for row in test_df.itertuples():\n",
    "    test_ds[row[1]-1, row[2]-1] = row[3]\n",
    "# test_ds = pd.DataFrame(test_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on train_df:\")\n",
    "print(train_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on test_df:\")\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using this function\n",
    "EPSILON = 1e-9\n",
    "\n",
    "def evaluate(test_ds, predicted_ds):\n",
    "    '''\n",
    "    Function for evaluating on MAE and RMSE\n",
    "    '''\n",
    "    # MAE\n",
    "    mask_test_ds = test_ds > 0\n",
    "    MAE = np.sum(np.abs(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32))\n",
    "\n",
    "    # RMSE\n",
    "    RMSE = np.sqrt(np.sum(np.square(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32)))\n",
    "\n",
    "    return MAE, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8743892654312901\n",
      "RMSE: 1.1141573193432484\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "MAE = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
    "RMSE = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
    "\n",
    "# predefined parameter for lambda value\n",
    "# Higher values of lamda - more weight to the average rating differences. i.e, more towards personalised CF\n",
    "# Lower values of lamda - more weight to user similarities. i.e, more towards slope one\n",
    "lamnbda = 0.2\n",
    "\n",
    "# Picking one active user to compare. Dataset is too huge, so to illustrate personalised weighted schema one active user is picked\n",
    "active_user = 0\n",
    "EPSILON = 1e-9\n",
    "\n",
    "\n",
    "# To store centered cosine similarity\n",
    "# As only calculating for one active user1-d array is used \n",
    "cos_similarities = np.zeros(train_ds.shape[0])\n",
    "\n",
    "# masking active user\n",
    "active_user_ratings = train_ds[active_user]\n",
    "\n",
    "for i in range(train_ds.shape[0]):\n",
    "    # Checking similarity with only other user, checking with same will always have high similarity\n",
    "    if i != active_user:\n",
    "        other_user_ratings = train_ds[i]\n",
    "        \n",
    "        # corrated ratings index, np.logical - https://numpy.org/doc/stable/reference/generated/numpy.logical_and.html and https://www.geeksforgeeks.org/numpy-logical_and-python/\n",
    "        corrated_ratings = np.logical_and(active_user_ratings > 0, other_user_ratings > 0)\n",
    "        \n",
    "        # Atleast one item should be corrated\n",
    "        if np.sum(corrated_ratings) > 0:\n",
    "            \n",
    "            # pearson correlation \n",
    "            sub_mean_active_ratings = active_user_ratings[corrated_ratings] - np.mean(active_user_ratings[corrated_ratings])\n",
    "            sub_mean_other_user_ratings = other_user_ratings[corrated_ratings] - np.mean(other_user_ratings[corrated_ratings])\n",
    "            \n",
    "            sub_mean_active_ratings_sq = np.square(sub_mean_active_ratings)\n",
    "            sub_mean_other_user_ratings_sq = np.square(sub_mean_other_user_ratings)\n",
    "            \n",
    "            sub_mean_active_ratings_sq_sumof_sq =  np.sqrt(np.sum(sub_mean_active_ratings_sq))\n",
    "            sub_mean_other_user_ratings_sq_sumof_sq =  np.sqrt(np.sum(sub_mean_other_user_ratings_sq))\n",
    "            \n",
    "            # formula from lectorial and lab to calculate centered cosine similarity\n",
    "            sim = np.sum(sub_mean_active_ratings * sub_mean_other_user_ratings) / (sub_mean_active_ratings_sq_sumof_sq * sub_mean_other_user_ratings_sq_sumof_sq + EPSILON)\n",
    "            \n",
    "            # Add to array\n",
    "            cos_similarities[i] = sim\n",
    "\n",
    "\n",
    "# compute deviations and cardinality\n",
    "# size -item*item\n",
    "dev = np.zeros((n_items, n_items))\n",
    "cardinality = np.zeros((n_items, n_items))\n",
    "\n",
    "for item_j in range(n_items):\n",
    "    for item_i in range(n_items):\n",
    "        \n",
    "        # every item i the user u has not rated\n",
    "        if item_i != item_j:\n",
    "            corrated_index = np.logical_and(train_ds[:, item_i] > 0, train_ds[:, item_j] > 0)\n",
    "            # compute cardinality \n",
    "            card_S = np.sum(corrated_index)\n",
    "            # skip if card_S is 0\n",
    "            if card_S == 0:\n",
    "                continue\n",
    "            # u_i - rating to item i, and u_j - rating to item j\n",
    "            u_j_ratings = train_ds[corrated_index, item_j]\n",
    "            u_i_ratings = train_ds[corrated_index, item_i]\n",
    "            \n",
    "            # computing given equation for deviation\n",
    "            slope_one_lamnbda = lamnbda * np.sum((u_j_ratings - u_i_ratings) / card_S)\n",
    "            \n",
    "            # exponet - cosine similarity value, base -2\n",
    "            expo = cos_similarities[np.where(corrated_index)[0]]\n",
    "            personalised_lamnbda = (1 - lamnbda)* (np.sum((u_j_ratings - u_i_ratings) * np.power(2, expo))/(np.sum(np.power(2,expo))*card_S)+EPSILON)\n",
    "            \n",
    "            # deviation as per given equation\n",
    "            dev[item_j, item_i] = slope_one_lamnbda + personalised_lamnbda\n",
    "            cardinality[item_j, item_i] = card_S\n",
    "\n",
    "\n",
    "# Predict Ratings\n",
    "prediction_matrix =np.zeros((n_users, n_items))\n",
    "for user in range(n_users):\n",
    "    for item in range(n_items):\n",
    "        # only rated by active user and only co rated items\n",
    "        mask_items = np.where(np.logical_and(train_ds[user] > 0, cardinality[item] > 0))[0]\n",
    "        \n",
    "        # If null, cannot predict\n",
    "        if len(mask_items) > 0:\n",
    "            # prediction accornding to given equation\n",
    "            prediction = np.sum((dev[mask_items, item] + train_ds[user, mask_items]) * cardinality[\n",
    "                mask_items, item]) / np.sum(cardinality[mask_items, item])\n",
    "            prediction_matrix[user, item] = prediction\n",
    "            # clip, lesser than zero to zero, larger than 5 to 5\n",
    "            prediction_matrix[user, item] = np.clip(prediction_matrix[user, item], 0, 5)\n",
    "\n",
    "MAE, RMSE = evaluate(test_ds, prediction_matrix)\n",
    "print(\"MAE:\", MAE) # got 0.87\n",
    "print(\"RMSE:\", RMSE) # got 1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0.8743892654312901, RMSE: 1.1141573193432484\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
